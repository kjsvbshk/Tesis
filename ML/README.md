# Machine Learning - Sistema de Predicciones NBA

## ğŸ“‹ Contexto del Proyecto

Esta carpeta `ML/` es parte de un sistema completo de **predicciones y apuestas virtuales para la NBA**. El proyecto estÃ¡ compuesto por varios mÃ³dulos que trabajan juntos:

### ğŸ—ï¸ Arquitectura del Sistema

```
Tesis/
â”œâ”€â”€ Backend/          # API FastAPI que usa los modelos ML para hacer predicciones
â”œâ”€â”€ Frontend/         # AplicaciÃ³n React/TypeScript para usuarios
â”œâ”€â”€ Scrapping/        # Sistema de extracciÃ³n de datos (NBA y Premier League)
â””â”€â”€ ML/              # â† ESTA CARPETA: Entrenamiento y gestiÃ³n de modelos ML
```

### ğŸ”„ Flujo de Datos

1. **Scrapping** â†’ Extrae datos de ESPN (partidos, estadÃ­sticas, lesiones, cuotas)
2. **ML** â†’ Entrena modelos con datos histÃ³ricos
3. **Backend** â†’ Carga modelos entrenados y genera predicciones en tiempo real
4. **Frontend** â†’ Muestra predicciones y permite apuestas virtuales

---

## ğŸ¯ Objetivo de esta Carpeta

Esta carpeta `ML/` estÃ¡ diseÃ±ada para:

- **Entrenar modelos de machine learning** para predecir resultados de partidos NBA
- **Gestionar versiones de modelos** (versionado)
- **Evaluar y comparar modelos** (mÃ©tricas, validaciÃ³n)
- **Exportar modelos entrenados** para uso en producciÃ³n (Backend)

---

## ğŸ¤– Modelos de Machine Learning

El sistema utiliza un **ensamble de modelos** para maximizar la precisiÃ³n:

### 1. RandomForest
- **Tipo**: ClasificaciÃ³n
- **Objetivo**: Predecir quiÃ©n ganarÃ¡ el partido (home/away)
- **Output**: Probabilidad de victoria de cada equipo

### 2. XGBoost
- **Tipo**: RegresiÃ³n
- **Objetivo**: Predecir cuÃ¡ntos puntos anotarÃ¡ cada equipo
- **Output**: PuntuaciÃ³n esperada (home_score, away_score)

### 3. Stacking Ensemble
- **Tipo**: Meta-modelo
- **Objetivo**: Combinar predicciones de RandomForest y XGBoost
- **Output**: PredicciÃ³n final con mayor confianza

---

## ğŸ“Š CaracterÃ­sticas (Features) que Usan los Modelos

Los modelos analizan las siguientes caracterÃ­sticas:

### CaracterÃ­sticas de Equipos
- **Rendimiento reciente**: Ãšltimos 5-10 partidos
- **Eficiencia ofensiva**: Puntos por posesiÃ³n, % de tiros anotados
- **Eficiencia defensiva**: Puntos permitidos, robos, bloqueos
- **EstadÃ­sticas de temporada**: Win/Loss record, diferencia de puntos

### CaracterÃ­sticas del Partido
- **Ventaja de localÃ­a**: Si juegan en casa o fuera
- **DÃ­as de descanso**: CuÃ¡ntos dÃ­as descansÃ³ cada equipo
- **Back-to-back**: Si un equipo juega partidos consecutivos
- **Head-to-head**: Historial entre los dos equipos

### CaracterÃ­sticas Externas
- **Lesiones**: Jugadores lesionados y su importancia
- **Cuotas de apuestas**: Probabilidades de casas de apuestas
- **Forma reciente**: Tendencia de victorias/derrotas

---

## ğŸ“ Estructura Recomendada

```
ML/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ CONTEXT.md                   # Resumen ejecutivo del contexto
â”œâ”€â”€ requirements.txt             # Dependencias especÃ­ficas de ML
â”œâ”€â”€ .gitignore                   # Archivos a ignorar en Git
â”‚
â”œâ”€â”€ data/                        # Datos para entrenamiento
â”‚   â”œâ”€â”€ raw/                     # Datos sin procesar (referencia a Scrapping)
â”‚   â”œâ”€â”€ processed/               # Datos procesados y listos para entrenar
â”‚   â””â”€â”€ features/                # Features engineering
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”‚
â”œâ”€â”€ src/                         # CÃ³digo fuente de ML
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # ConfiguraciÃ³n (lee .env)
â”‚   â”œâ”€â”€ data_loader.py           # Cargar datos desde PostgreSQL
â”‚   â”œâ”€â”€ feature_engineering.py   # Crear features
â”‚   â”œâ”€â”€ models/                  # DefiniciÃ³n de modelos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”‚   â””â”€â”€ ensemble.py
â”‚   â”œâ”€â”€ training/                # Scripts de entrenamiento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py             # Script principal de entrenamiento
â”‚   â”‚   â””â”€â”€ train_ensemble.py
â”‚   â””â”€â”€ evaluation/              # EvaluaciÃ³n de modelos
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ validation.py
â”‚
â”œâ”€â”€ scripts/                     # Scripts utilitarios
â”‚   â”œâ”€â”€ test_connection.py       # Probar conexiÃ³n a BD
â”‚   â”œâ”€â”€ export_model.py          # Exportar modelo para Backend
â”‚   â”œâ”€â”€ register_model_version.py # Registrar versiÃ³n en BD
â”‚   â””â”€â”€ compare_models.py        # Comparar versiones
â”‚
â”œâ”€â”€ models/                      # Modelos entrenados (exportados)
â”‚   â”œâ”€â”€ nba_prediction_model_v1.0.0.joblib
â”‚   â”œâ”€â”€ nba_prediction_model_v1.1.0.joblib
â”‚   â””â”€â”€ metadata/                # Metadatos de cada modelo
â”‚       â”œâ”€â”€ v1.0.0_metadata.json
â”‚       â””â”€â”€ v1.1.0_metadata.json
â”‚
â””â”€â”€ tests/                       # Tests unitarios
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_feature_engineering.py
    â””â”€â”€ test_models.py
```

---

## ğŸ”Œ IntegraciÃ³n con Backend

### CÃ³mo el Backend Carga los Modelos

El Backend busca modelos en la ruta:
```
Backend/ml/models/nba_prediction_model_{version}.joblib
```

**Ejemplo:**
- Modelo versiÃ³n `v1.0.0` â†’ `Backend/ml/models/nba_prediction_model_v1.0.0.joblib`
- Si no encuentra versiÃ³n especÃ­fica â†’ `Backend/ml/models/nba_prediction_model.joblib`

### Sistema de Versionado

El Backend usa la tabla `app.model_versions` (o `sys.model_versions` segÃºn configuraciÃ³n) para gestionar versiones:

```python
# ModelVersion en Backend/app/models/model_version.py
- id: int
- version: str (e.g., "v1.0.0")
- is_active: bool (solo una versiÃ³n activa)
- model_metadata: JSON (mÃ©tricas, features, etc.)
- description: str
- created_at: datetime
```

**Flujo de despliegue:**
1. Entrenar modelo en `ML/`
2. Exportar a `Backend/ml/models/`
3. Registrar versiÃ³n en BD (tabla `model_versions`)
4. Activar versiÃ³n (marcar `is_active=True`)

---

## ğŸ“š Fuentes de Datos

### Base de Datos Neon (Cloud)

El sistema usa **Neon PostgreSQL** (cloud) con mÃºltiples esquemas:

1. **Esquema `espn`**: Datos extraÃ­dos por Scrapping
   - `games` - Partidos y resultados
   - `team_stats` - EstadÃ­sticas de equipos
   - `player_stats` - EstadÃ­sticas de jugadores
   - `standings` - Clasificaciones
   - `injuries` - Lesiones
   - `odds` - Cuotas de apuestas

2. **Esquema `sys` o `app`**: Datos del sistema
   - `model_versions` - Versiones de modelos
   - `predictions` - Predicciones generadas
   - `requests` - Requests de predicciones

3. **Esquema `ml`**: Datos procesados para ML
   - `ml_ready_games` - **Tabla principal** con features listas para entrenamiento
     - Columnas base: game_id, fecha, equipos, scores, stats base
     - Rolling features: home_ppg_last5, away_ppg_last5, home_net_rating_last10, away_net_rating_last10
     - Rest days: home_rest_days, away_rest_days
     - Injuries: home_injuries_count, away_injuries_count
     - Odds: implied_prob_home, implied_prob_away
     - Target: home_win (boolean)

**ConfiguraciÃ³n:**
- **Neon (cloud)**: Configurado en variables `NEON_*` en `.env`
- **Esquema ML**: Se crea con `scripts/init_ml_schema.py`
- **Nota**: Solo se usa Neon, no hay bases de datos locales

### Datos Procesados

El sistema de Scrapping genera datasets consolidados:
- `Scrapping/nba/data/processed/nba_full_dataset.csv`
- `Scrapping/premier_league/data/processed/premier_league_full_dataset.csv`

---

## ğŸ“‹ Fases de Desarrollo

### âœ… FASE 1: Definir y crear la tabla objetivo `ml_ready_games`

**Objetivo**: Consolidar en una Ãºnica tabla la fila por partido con columnas base y espacio para features.

**Scripts**:
- `scripts/create_ml_ready_games.py` - Crea la tabla y la pobla desde `espn.games`
- `scripts/verify_ml_ready_games.py` - Verifica la estructura y datos

**Estado**: âœ… Completada
- Tabla `ml.ml_ready_games` creada con 1,237 registros
- Columnas base y placeholders para features implementadas

### âœ… FASE 2: Feature Engineering BÃ¡sico y Rolling Features

**Objetivo**: Calcular features temporales (Ãºltimos N partidos), rest days, injury counts, implied probs.

**Scripts**:
- `src/etl/build_features.py` - Script principal de feature engineering
- `scripts/verify_features.py` - VerificaciÃ³n de features calculadas
- `scripts/check_phase2.py` - Checks finales de la Fase 2

**Features implementadas**:
- âœ… Rolling features: `home_ppg_last5`, `away_ppg_last5`, `home_net_rating_last10`, `away_net_rating_last10` (100% aplicado)
- âœ… Rest days: `home_rest_days`, `away_rest_days` (99% aplicado)
- âœ… Injuries: `home_injuries_count`, `away_injuries_count` (100% aplicado)
- âœ… Implied probabilities: `implied_prob_home`, `implied_prob_away` (1% aplicado, limitado por datos disponibles)

**Estado**: âœ… Completada
- Todas las features calculadas y actualizadas en `ml.ml_ready_games`
- Script idempotente (se puede ejecutar mÃºltiples veces)

### âœ… FASE 3: Dataset Final y Pruebas de Calidad (Data Quality)

**Objetivo**: Validar el dataset para evitar fugas de informaciÃ³n y problemas de orden temporal.

**Scripts**:
- `src/etl/validate_data_quality.py` - ValidaciÃ³n completa de calidad de datos
- `scripts/phase3_summary.py` - Resumen ejecutivo de la Fase 3

**Validaciones realizadas**:
- âœ… No leakage: VerificaciÃ³n de que ninguna feature use valores posteriores a la fecha del juego
- âœ… Nulos crÃ­ticos: VerificaciÃ³n de que el target (`home_win`) no tenga NULLs
- âœ… DistribuciÃ³n del target: VerificaciÃ³n de balance (56.99% home wins, 43.01% away wins)
- âœ… Integridad de joins: VerificaciÃ³n de correspondencia con `espn.games`
- âœ… Validaciones adicionales: Rangos de valores, duplicados, etc.

**Estado**: âœ… Completada
- Dataset validado y listo para ML
- Todos los checks pasaron exitosamente

---

## ğŸš€ GuÃ­a de Uso RÃ¡pido

### 1. InstalaciÃ³n

```bash
cd ML
pip install -r requirements.txt
```

### 2. Inicializar Esquema ML y Crear Tabla Base

```bash
# Crear el esquema ML en Neon
python scripts/init_ml_schema.py

# Crear y poblar la tabla ml_ready_games (Fase 1)
python scripts/create_ml_ready_games.py

# Verificar la tabla creada
python scripts/verify_ml_ready_games.py
```

### 2.1. Feature Engineering (Fase 2)

```bash
# Calcular rolling features, rest days, injuries, odds
python src/etl/build_features.py

# Verificar features calculadas
python scripts/verify_features.py
python scripts/check_phase2.py
```

### 2.2. ValidaciÃ³n de Calidad (Fase 3)

```bash
# Validar calidad del dataset
python src/etl/validate_data_quality.py

# Ver resumen ejecutivo
python scripts/phase3_summary.py
```

### 3. Probar ConexiÃ³n a Base de Datos

```bash
# Probar conexiones a todas las bases de datos configuradas
python scripts/test_connection.py
```

### 4. Cargar Datos

```python
from src.data_loader import load_nba_data, DataLoader

# OpciÃ³n 1: FunciÃ³n de conveniencia (carga desde CSV si existe, sino desde Neon)
df = load_nba_data(
    season_start="2023-10-01",
    season_end="2024-06-30",
    from_csv=True    # Intentar cargar desde CSV primero
)

# OpciÃ³n 2: Usar DataLoader directamente
loader = DataLoader(schema="espn")  # Esquema ESPN en Neon

# Cargar partidos
games = loader.load_games(
    season_start="2023-10-01",
    season_end="2024-06-30",
    limit=1000
)

# Cargar estadÃ­sticas de equipos
team_stats = loader.load_team_stats(season="2023-24")

# Cargar clasificaciones
standings = loader.load_standings(season="2023-24")

# Cargar dataset consolidado (desde CSV o construir desde BD)
df = loader.load_consolidated_dataset(
    season_start="2023-10-01",
    season_end="2024-06-30"
)
```

### 5. Entrenar Modelo

```python
from src.training.train import train_model

model, metrics = train_model(
    data=df,
    model_type="ensemble",
    version="v1.0.0"
)

# Exportar modelo
from scripts.export_model import export_model
export_model(model, version="v1.0.0", metrics=metrics)
```

### 6. Registrar en Backend

```python
from scripts.register_model_version import register_model_version

register_model_version(
    version="v1.0.0",
    model_path="models/nba_prediction_model_v1.0.0.joblib",
    metadata=metrics,
    description="Primera versiÃ³n del modelo ensemble",
    activate=True  # Activar esta versiÃ³n
)
```

---

## ğŸ”— Referencias a Otras Carpetas

### Backend
- **PredicciÃ³n en producciÃ³n**: `Backend/app/services/prediction_service.py`
- **Carga de modelos**: LÃ­nea 60-66 de `prediction_service.py`
- **Modelo de versiÃ³n**: `Backend/app/models/model_version.py`
- **Endpoint de predicciones**: `Backend/app/api/v1/endpoints/predictions.py`

### Scrapping
- **Datos de entrenamiento**: `Scrapping/nba/data/processed/nba_full_dataset.csv`
- **ConexiÃ³n a BD**: `Scrapping/nba/utils/db.py`
- **ETL**: `Scrapping/nba/etl/transform_consolidate.py`

### Frontend
- **Consumo de predicciones**: `Frontend/src/services/predictions.service.ts`
- **VisualizaciÃ³n**: `Frontend/src/pages/PredictionsPage.tsx`

---

## ğŸ“ Notas Importantes

### Formato de Modelos

Los modelos deben exportarse en formato **joblib** (compatible con scikit-learn):

```python
import joblib

# Guardar modelo
joblib.dump(model, "models/nba_prediction_model_v1.0.0.joblib")

# El Backend carga asÃ­:
model = joblib.load("models/nba_prediction_model_v1.0.0.joblib")
```

### Estructura de PredicciÃ³n

El modelo debe retornar un diccionario con:

```python
{
    "home_win_probability": float,      # 0.0 - 1.0
    "away_win_probability": float,      # 0.0 - 1.0
    "predicted_home_score": float,      # Puntos esperados
    "predicted_away_score": float,      # Puntos esperados
    "predicted_total": float,           # Total de puntos
    "recommended_bet": str,             # "home", "away", "none"
    "expected_value": float,            # Valor esperado
    "confidence_score": float,          # 0.0 - 1.0
    "model_version": str,               # VersiÃ³n del modelo
    "prediction_timestamp": datetime,
    "features_used": dict               # Features utilizadas
}
```

### Variables de Entorno

El proyecto usa el mismo archivo `.env` que el Backend (ubicado en la raÃ­z del proyecto `Tesis/`). Las variables incluyen:

**Base de datos Neon (cloud):**
- `NEON_DB_HOST`, `NEON_DB_PORT`, `NEON_DB_NAME`, `NEON_DB_USER`, `NEON_DB_PASSWORD`
- `NEON_DB_SSLMODE`, `NEON_DB_CHANNEL_BINDING`

**Esquemas:**
- `NBA_DB_SCHEMA` - Esquema ESPN (por defecto: `espn`)
- `DB_SCHEMA` - Esquema del sistema (por defecto: `sys`)
- `ML_DB_SCHEMA` - Esquema ML (por defecto: `ml`)

**Nota**: 
- El archivo `.env` ya estÃ¡ creado en la raÃ­z del proyecto. Los scripts de ML lo leen automÃ¡ticamente.
- Solo se usa Neon (cloud), no hay bases de datos locales.

---

## ğŸ§ª Testing

```bash
# Ejecutar tests
pytest tests/

# Con cobertura
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ“ˆ PrÃ³ximos Pasos

1. **Crear estructura de carpetas** segÃºn la recomendaciÃ³n âœ…
2. **Implementar data_loader.py** para cargar datos desde PostgreSQL âœ…
3. **Implementar feature_engineering.py** para crear features
4. **Entrenar modelos** (RandomForest, XGBoost, Ensemble)
5. **Evaluar modelos** con mÃ©tricas apropiadas
6. **Exportar modelos** en formato joblib
7. **Integrar con Backend** registrando versiones

---

## ğŸ“– DocumentaciÃ³n Adicional

- **Backend README**: `../Backend/README.md`
- **Scrapping README**: `../Scrapping/README.md`
- **Frontend README**: `../Frontend/README.md`
- **Contexto del proyecto**: `CONTEXT.md`

---

## âš ï¸ Consideraciones

- **Datos histÃ³ricos**: AsegÃºrate de tener suficientes datos (mÃ­nimo 2-3 temporadas)
- **Features**: Las features deben estar disponibles en tiempo de predicciÃ³n
- **Versionado**: Siempre versiona tus modelos antes de desplegar
- **ValidaciÃ³n**: Valida modelos con datos de temporadas diferentes
- **Retraining**: Considera retrenar modelos periÃ³dicamente (cada temporada)

---

**Ãšltima actualizaciÃ³n**: 2024
**VersiÃ³n del documento**: 1.0.0
